{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Doing NLP with Keras and embeddings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-14 08:19:03.141343: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-14 08:19:03.141457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Preprocessing**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "tf.keras.layers.TextVectorization(\n",
    "    max_tokens=None,  \n",
    "    standardize='lower_and_strip_punctuation',  \n",
    "    split='whitespace',  \n",
    "    ngrams=None, output_mode='int',  \n",
    "    output_sequence_length=None,  \n",
    "    pad_to_max_tokens=False,  \n",
    "    vocabulary=None, **kwargs  \n",
    ")\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Dataset\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-14 08:19:06.162544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-14 08:19:06.162608: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-14 08:19:06.162629: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CE43859): /proc/driver/nvidia/version does not exist\n",
      "2021-09-14 08:19:06.164311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=1000, standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace', ngrams=None, output_mode='int',\n",
    "    output_sequence_length=10, pad_to_max_tokens=False, vocabulary=None\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "vectorizer.adapt(text_dataset.batch(32))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-14 08:19:06.934532: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# We can have a look at the vocabulary index\n",
    "vectorizer.get_vocabulary()[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '[UNK]', 'foo', 'baz', 'bar']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# If we vectorize a sentence we get\n",
    "output = vectorizer([['baz bar hippo']])\n",
    "output.numpy()[0, :6]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 4, 1, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Embedding**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Build a model with Embeddings and Recurrent layers\n",
    "model = tf.keras.Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "tf.keras.layers.Embedding(\n",
    "    input_dim,\n",
    "    output_dim,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=False,\n",
    "    input_length=None,\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.add(vectorizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.add(tf.keras.layers.Embedding(\n",
    "    input_dim=1000,\n",
    "    output_dim=64,\n",
    "    input_length=10\n",
    "))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model.compile('rmsprop', 'mse')\n",
    "model.predict([['foo nice'], ['bar trumpet']])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[-0.00563084,  0.0093014 , -0.01204   , ..., -0.00744009,\n",
       "         -0.04828423, -0.02074393],\n",
       "        [ 0.0312037 , -0.03578164,  0.0426073 , ..., -0.04811623,\n",
       "         -0.04159303,  0.01463152],\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623],\n",
       "        ...,\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623],\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623],\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623]],\n",
       "\n",
       "       [[-0.02593101, -0.03805034,  0.00801908, ...,  0.02699113,\n",
       "         -0.01994164, -0.01764347],\n",
       "        [ 0.0312037 , -0.03578164,  0.0426073 , ..., -0.04811623,\n",
       "         -0.04159303,  0.01463152],\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623],\n",
       "        ...,\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623],\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623],\n",
       "        [-0.00287954,  0.01475239, -0.02184997, ...,  0.03118464,\n",
       "         -0.03309283,  0.02958623]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Using a whole CNN model\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "model.add(layers.Conv1D(2, 1, activation=\"relu\"))\n",
    "model.add(layers.Conv1D(2, 1, activation=\"relu\"))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "# Densly connected final layers\n",
    "model.add(layers.Dense(12, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\", name=\"predictions\"))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# model.fit(..)\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 64)            64000     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 10, 2)             130       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 10, 2)             6         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                36        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 64,185\n",
      "Trainable params: 64,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Or use it in an LSTM model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorizer)\n",
    "model.add(tf.keras.layers.Embedding(\n",
    "    input_dim=1000,\n",
    "    output_dim=64,\n",
    "    input_length=10\n",
    "))\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\", name=\"predictions\"))\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 64)            64000     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 10, 128)           66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 228,993\n",
      "Trainable params: 228,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bi_deep_learning-M-dGzlNK': pipenv)"
  },
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}