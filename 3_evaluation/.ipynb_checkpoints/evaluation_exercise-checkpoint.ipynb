{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercise contains a number of challenges to test your knowledge from the theory session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"axes.titlecolor\" on line 99 in\n",
      "C:\\Users\\nunezs\\Downloads\\ML\\3_evaluation\\matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.labelcolor\" on line 109 in\n",
      "C:\\Users\\nunezs\\Downloads\\ML\\3_evaluation\\matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.labelcolor\" on line 111 in\n",
      "C:\\Users\\nunezs\\Downloads\\ML\\3_evaluation\\matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.titlecolor\" on line 99 in\n",
      "matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.labelcolor\" on line 109 in\n",
      "matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.labelcolor\" on line 111 in\n",
      "matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# Setup the matplotlib styling\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "\n",
    "try:\n",
    "    # Try to use the BI style sheet for plots\n",
    "    plt.style.use('matplotlibrc')\n",
    "    plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[(136/256, 76/256, 255/256), (60/256, 170/256, 207/256), (12/256, 229/256, 177/256)]) \n",
    "    \n",
    "    colors = [(0.53125, 0.296875, 0.99609375), (0.453125, 0.3984375, 0.9453125), (0.375, 0.4921875, 0.89453125), (0.3046875, 0.578125, 0.8515625), (0.234375, 0.6640625, 0.80859375), (0.16015625, 0.75390625, 0.76171875), (0.09375, 0.8359375, 0.72265625), (0.046875, 0.89453125, 0.69140625), (0.0, 0.875, 0.6640625)]\n",
    "    bicmap = LinearSegmentedColormap.from_list(name='BIcmp', \n",
    "                                                colors=colors,\n",
    "                                                N=len(colors))\n",
    "    cm_bright = ListedColormap([(0.53125, 0.296875, 0.99609375), (12/256, 229/256, 177/256)])\n",
    "except:\n",
    "    bicmap = plt.cm.BuGn \n",
    "    colors = ['r', 'g', 'b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1:\n",
    "A colleague of yours who has not yet participated in the BI Data Science Academy has already trained models for 2 different problems. The training data used to train the models is provided in the files *_train.csv, where * is either a or b. The models are provided in *_model.py and the test data is provided in *_test.csv.\n",
    "\n",
    "For each of the two cases a and b …\n",
    "\n",
    "a)\t… go through the data and see what kind of prediction problem the data is about (classification or regression).  \n",
    "b)\t… evaluate the model on the test dataset. Should the model be put into production? If so, why do you think so? If not, how can you fix the existing models or retrain a new model that will perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mean_absolute_percentage_error' from 'sklearn.metrics' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7e4a2eb7ee52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Available metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Tip: Using the square root operation of numpy (.sqrt), we can get the root mean squared error from the mean squared error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mean_absolute_percentage_error' from 'sklearn.metrics' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Available metrics\n",
    "# Tip: Using the square root operation of numpy (.sqrt), we can get the root mean squared error from the mean squared error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix, accuracy_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3.1.1: Model A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data of model a and storing it in variables\n",
    "a_data = pd.read_csv('data/a_test.csv')\n",
    "a_features = a_data[a_data.columns.difference(['target'])].values\n",
    "a_target = a_data['target'].astype(int).values\n",
    "a_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the problem a classification or regression problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model a\n",
    "from models.a_model import a_model\n",
    "\n",
    "# Perform a prediction on the test set\n",
    "# TODO\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should the model be put into production? If so, why do you think so? If not, how can you fix the existing models or retrain a new model that will perform better?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3.1.2: Model B**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data of model b and storing it in convenient variables\n",
    "b_data = pd.read_csv('data/b_test.csv')\n",
    "b_features = b_data[b_data.columns.difference(['flight_length_minutes'])].values\n",
    "b_target = b_data['flight_length_minutes'].values\n",
    "b_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the problem a classification or regression problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model b\n",
    "from models.b_model import b_model\n",
    "\n",
    "# Perform a prediction with model b on the test data\n",
    "# TODO\n",
    "\n",
    "# Evalaute the performance of model b\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should the model be put into production? If so, why do you think so? If not, how can you fix the existing models or retrain a new model that will perform better?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification model (that outputs confidence and not a Boolean prediction) was evaluated on a test dataset. The results are as follows:\n",
    "\n",
    "| Prediciton| Actual Value|\n",
    "| ---------:|------:|\n",
    "| 0.02      | False |\n",
    "| 0.05      | True  |\n",
    "| 0.09      | False |\n",
    "| 0.12      | False |\n",
    "| 0.19      | False |\n",
    "| 0.21      | False |\n",
    "| 0.23      | True  |\n",
    "| 0.91      | True  |\n",
    "| 0.91      | True  |\n",
    "| 0.99      | True  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3.2.1:** Plot the ROC curve of that predictor using the critical values 0, 0.1, 0.2, 0.9 and 1. Is the model of good quality?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(\n",
    "    {\n",
    "        'Prediction': [0.02, 0.05, 0.09, 0.12, 0.19, 0.21, 0.23, 0.91, 0.91, 0.99],\n",
    "        'Actual Value': [0, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    }\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds\n",
    "# TODO\n",
    "# Collect the tpr and fpr in a list\n",
    "# TODO\n",
    "# Iterate through all threshold\n",
    "# TODO\n",
    "\n",
    "# Everything above the threshold is classififed as true\n",
    "# TODO\n",
    "# Tip: Use the confusion_matrix() to calculate the tp, fp, n and p value for you\n",
    "# TODO\n",
    "# Calculate the true positive rate\n",
    "# TODO\n",
    "# Calculate the true negative rate\n",
    "# TODO\n",
    "# Add your values to the lists\n",
    "# TODO\n",
    "\n",
    "# Plot the results\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the model of good quality?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3.2.2:**\tWhich critical values would you recommend for an application in the real world if…\n",
    "1.\tPredicting a data row as TRUE is cheap\n",
    "2.\tPredicting a data row as TRUE is expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
