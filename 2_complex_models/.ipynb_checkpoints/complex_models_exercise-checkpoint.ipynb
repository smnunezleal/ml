{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Complex Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will apply the machine learning models, we saw in todays exercise.\n",
    "We will visualize the learned rules of the models with the `plot_decision_boundaries()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"axes.titlecolor\" on line 99 in\n",
      "C:\\Users\\nunezs\\Downloads\\ML\\2_complex_models\\matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.labelcolor\" on line 109 in\n",
      "C:\\Users\\nunezs\\Downloads\\ML\\2_complex_models\\matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.labelcolor\" on line 111 in\n",
      "C:\\Users\\nunezs\\Downloads\\ML\\2_complex_models\\matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.titlecolor\" on line 99 in\n",
      "matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.labelcolor\" on line 109 in\n",
      "matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.labelcolor\" on line 111 in\n",
      "matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Try to use the BI style sheet for plots\n",
    "    plt.style.use('matplotlibrc')\n",
    "    plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[(136/256, 76/256, 255/256), (60/256, 170/256, 207/256), (12/256, 229/256, 177/256)]) \n",
    "    \n",
    "    colors = [(0.53125, 0.296875, 0.99609375), (0.453125, 0.3984375, 0.9453125), (0.375, 0.4921875, 0.89453125), (0.3046875, 0.578125, 0.8515625), (0.234375, 0.6640625, 0.80859375), (0.16015625, 0.75390625, 0.76171875), (0.09375, 0.8359375, 0.72265625), (0.046875, 0.89453125, 0.69140625), (0.0, 0.875, 0.6640625)]\n",
    "    bicmap = LinearSegmentedColormap.from_list(name='BIcmp', \n",
    "                                                colors=colors,\n",
    "                                                N=len(colors))\n",
    "    cm_bright = ListedColormap([(0.53125, 0.296875, 0.99609375), (12/256, 229/256, 177/256)])\n",
    "except:\n",
    "    bicmap = plt.cm.BuGn \n",
    "    colors = ['r', 'g', 'b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2.1: Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exercise we use a regression problem and test different models and compare how well they fit the true target function.\n",
    "\n",
    "Explain the fit of the different models.\n",
    "Which model would you use to solve this particular problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = pd.read_csv('data_regression.csv')\n",
    "reg_features = reg_data[['x']].values\n",
    "reg_target = reg_data['y'].values\n",
    "reg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "reg_data.plot.scatter(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot the learned function and compare it to the true function\n",
    "def plot_regression(rg, features, target):\n",
    "    x_lin = np.linspace(features.min(), features.max(), 100)\n",
    "\n",
    "    plt.scatter(features, rg.predict(features), color=(136/256, 76/256, 255/256), s=19, marker='o', label=\"prediction\")\n",
    "    plt.plot(x_lin, rg.predict(x_lin.reshape(-1, 1)), color=(60/256, 170/256, 207/256), linewidth=2, label=\"smooth prediction\")\n",
    "    plt.scatter(features, target, color=(12/256, 229/256, 177/256), s=19, marker='o', label=\"y\")\n",
    "    plt.plot(x_lin, np.sin(x_lin), color=(12/256, 229/256, 177/256), linewidth=2, label=\"true function\")\n",
    "\n",
    "\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.1.1: Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearRegression model\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LinearRegression model\n",
    "# TODO\n",
    "# Fit the model on the data\n",
    "# TODO\n",
    "# Plot the learned function\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.1.2: Polynomial Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PolynomialFeatures class\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the PolynomialFeatures\n",
    "# TODO\n",
    "# Use fit_transform to convert data into polynomial features\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a LinearRegression model\n",
    "# TODO\n",
    "# Train the LinearRegression model on the polynomial features\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this setup we can't use plot_regression(), because the function poly_reg uses a different datasets\n",
    "# Instead can create a pipeline that takes the original dataset and converts it into polynomial feature space before feeding it to the linear regression model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Use make_pipeline() to create a pipeline of PolynomialFeatures() and LinearRegression() by passing instances of these two classes to make_pipeline()\n",
    "# TODO\n",
    "# The pipeline can now be treated as a LinearRegression model\n",
    "# Fit the pipeline with the original regression dataset\n",
    "# TODO\n",
    "# Pass the pipeline to the plot_regression() function together with the original regression dataset\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to adjust the number of polynomials with PolynomialFeatures(x), where x is maximum degree of polynomial features.**\n",
    "Which degree fits the data best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.1.3: SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Support Vector Regressor (SVR)\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVR model\n",
    "# TODO\n",
    "# Fit the Support Vector Machine\n",
    "# TODO\n",
    "# Plot the learned regression function\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2.2: Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit each of the models and visualize the decision boundary. How does the theory behind the learning algorithm explain the decision boundaries you see in the plots?\n",
    "\n",
    "Finally, decide which model you would use to solve this particular problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "# Split into feature columns\n",
    "features = data[['x', 'y']].values\n",
    "# And the target column\n",
    "target = data['z'].astype(int).values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "data.plot.scatter(x='x', y='y', c=data['z'], colormap=cm_bright, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting the decision boundaries of a trained model\n",
    "def plot_decision_boundaries(clf, x, y):\n",
    "    h = 0.02  \n",
    "\n",
    "    x_min, x_max = x[:, 0].min() - .5, x[:, 0].max() + .5\n",
    "    y_min, y_max = x[:, 1].min() - .5, x[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                            np.arange(y_min, y_max, h))\n",
    "\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=bicmap, alpha=.8)\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cm_bright, edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.2.1: Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DecisionTree\n",
    "# TODO\n",
    "# Fit the decision tree on the data\n",
    "# TODO\n",
    "# Plot the DecisionTree's decision boundaries\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.2.2: RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "# TODO\n",
    "# Fit the random forest on the data\n",
    "# TODO\n",
    "# Plot the random forest decision boundaries\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.1.3: Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GradientBoostingClassifier\n",
    "# TODO\n",
    "# Fit the gradient boosting model on the data\n",
    "# TODO\n",
    "# Plot the ensemble decision boundaries\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2.2.4: Multi-layer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLPClassifier\n",
    "# TODO\n",
    "# Fit the neural network on the data\n",
    "# TODO\n",
    "# Plot the mlp decision boundaries\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bonus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of models we haven't applied yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the following models to the regression problem used above:\n",
    "- DecisionTreeRegressor (from sklearn.tree import DecisionTreeRegressor)\n",
    "- Mulit-layer Perceptron Regressor (from sklearn.neural_network import MLPRegressor)\n",
    "- Random Forest Regressor (from sklearn.ensemble import RandomForestRegressor)\n",
    "- Gradient Boosting Regressor (from sklearn.ensemble import GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import the model, initialize it, fit it and evaluate it with plot_regression()\n",
    "# Repeat the above steps for the other models\n",
    "# Tip: You might want to use a loop for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Apply the following models to the classification problem we used previously\n",
    "- Logistic Regression (from sklearn.linear_model import LogisticRegression)\n",
    "- Support Vector Classifier (SVC) (from sklearn.svm import SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply the models to a number of different datasets and see how the results differ.\n",
    "Apply the above models to the following datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_circles, make_moons\n",
    "\n",
    "x, y = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)\n",
    "x += 2 * np.random.default_rng(2).uniform(size=x.shape)\n",
    "dataset2 = (x, y)\n",
    "\n",
    "dataset3 = make_moons(noise=0.3, random_state=0)\n",
    "\n",
    "dataset4 = make_circles(noise=0.2, factor=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import the model, initialize it, fit it on one of the datasets and plot the decision boundaries\n",
    "# Repeat the above steps for the other models\n",
    "# Tip: You might want to use a loop for this"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
