{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Building Deep Learning Models in Keras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow tensorflow-datasets"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (4.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: keras~=2.6 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.40.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (1.2.0)\n",
      "Requirement already satisfied: promise in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: dill in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (0.3.4)\n",
      "Requirement already satisfied: future in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (0.18.2)\n",
      "Requirement already satisfied: importlib-resources in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (5.2.2)\n",
      "Requirement already satisfied: tqdm in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (4.62.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-datasets) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from importlib-resources->tensorflow-datasets) (3.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-12 17:21:13.546608: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-12 17:21:13.546642: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# In keras models consist of layers\n",
    "# Each layer takes a size (number of neurons), and can have a activation function and a name\n",
    "layer1 = layers.Dense(2, activation='relu', name='layer1')\n",
    "# An Input can be used to specify the input size 3\n",
    "x = layers.Input(3, name='input')\n",
    "# We can stack layers by passing it to the __call__ function of the object\n",
    "model = layer1(x)\n",
    "layer2 = layers.Dense(3, activation='relu', name='layer2')\n",
    "model = layer2(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-12 17:21:16.491668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-12 17:21:16.491729: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-12 17:21:16.491748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CE43859): /proc/driver/nvidia/version does not exist\n",
      "2021-09-12 17:21:16.492025: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# A more readable way is to use Sequential models\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(3, name='Input'),\n",
    "        layers.Dense(2, activation='relu', name='layer1'),\n",
    "        layers.Dense(3, activation='relu', name='layer2')\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Or another way would be\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', name='layer1'))\n",
    "model.add(layers.Dense(3, activation='relu', name='layer2'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# We can simply pass through a vector\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# We can look at it for debugging purposes with\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (3, 2)                    8         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 3)                    9         \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# But actually we want to train the model\n",
    "# First, we need to compile it\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Possible optimizers can be found here: https://keras.io/api/optimizers/\n",
    "# And loss functions here: https://keras.io/api/losses/\n",
    "# For binary classification problems use: BinaryCrossentropy loss\n",
    "# For classification problems use: SparseCategoricalCrossentropy loss\n",
    "# For regression problems use: MeanSquaredError loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Then we can fit it\n",
    "# specifying a validation data set\n",
    "history = model.fit(\n",
    "    x=tf.ones((3, 3)),\n",
    "    y=tf.ones(3),\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(tf.ones((3, 3)), tf.ones(3)),\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-12 17:21:17.396038: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Evaluate the model on test data\n",
    "results = model.evaluate(tf.ones((3, 3)), tf.ones(3), batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.0000e+00\n",
      "test loss, test acc: [1.0986123085021973, 0.0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# We can make predictions with\n",
    "predictions = model.predict(tf.ones((3, 3)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# For transfer learning we can \n",
    "# Remove the classification layer from the model\n",
    "model.pop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create a new model with a new classification layer\n",
    "model = keras.Sequential([model, layers.Dense(10)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile and train (this will only update the weights of the last layer).\n",
    "\n",
    "# Alternatively\n",
    "# Freeze the base model\n",
    "model.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# We can also build Convoluational models\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(28, 28, 1)))  # 28x28 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "# to add classification layer we first need to create a one dimensional feature vector\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bi_deep_learning-M-dGzlNK': pipenv)"
  },
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}