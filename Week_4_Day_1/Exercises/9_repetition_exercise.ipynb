{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Module 9: Repetition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In an effort to modernize our sales process, management wants to target the advertisment for customers better. Market research has concluded that this kind of advertisment is best used when the customer is in the process of ordering new products.\n",
    "\n",
    "Our task is to build system that predicts the time when a customer orders the next batch.\n",
    "\n",
    "For this we need to:\n",
    "- Analyze the historic data to identify features that can be used for prediction\n",
    "- Preprocess the data for the following steps\n",
    "- Build our system or model for prediction\n",
    "- Evaluate the feasability of the idea "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "from pandas.core.algorithms import value_counts\n",
    "\n",
    "try:\n",
    "    # Try to use the BI style sheet for plots\n",
    "    plt.style.use('matplotlibrc')\n",
    "    plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[(136/256, 76/256, 255/256), (60/256, 170/256, 207/256), (12/256, 229/256, 177/256)]) \n",
    "    \n",
    "    colors = [(0.53125, 0.296875, 0.99609375), (0.453125, 0.3984375, 0.9453125), (0.375, 0.4921875, 0.89453125), (0.3046875, 0.578125, 0.8515625), (0.234375, 0.6640625, 0.80859375), (0.16015625, 0.75390625, 0.76171875), (0.09375, 0.8359375, 0.72265625), (0.046875, 0.89453125, 0.69140625), (0.0, 0.875, 0.6640625)]\n",
    "    bicmap = LinearSegmentedColormap.from_list(name='BIcmp', \n",
    "                                                colors=colors,\n",
    "                                                N=len(colors))\n",
    "    cm_bright = ListedColormap([(0.53125, 0.296875, 0.99609375), (12/256, 229/256, 177/256)])\n",
    "except:\n",
    "    bicmap = plt.cm.BuGn \n",
    "    colors = ['r', 'g', 'b']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 9.1: Exploratory Data Analysis**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have the following two datasets available:\n",
    "- `Customers`: Contains the data about the contact person that makes the orders.\n",
    "- `Order History`: Contains the orders placed by each person for the past 1000 days."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Make yourself familiar with the data**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the dataset\n",
    "customers = pd.read_csv(\n",
    "    'customers.csv',\n",
    "    index_col='customer_id',\n",
    "    parse_dates=['birth_date', 'customer_since'])\n",
    "customers.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "order_history = pd.read_csv(\n",
    "    'order_history.csv',\n",
    "    index_col=[0, 1],\n",
    "    parse_dates=True)\n",
    "order_history.index.names = ['target', 'customer_id']\n",
    "order_history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define which variables you want to use as features\n",
    "features = ['country', 'customer_since', 'client_group']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The target variable will be the number of days between each order from each customer\n",
    "target = order_history.reset_index(level=0).groupby(level=0).diff().dropna()['target'].dt.days\n",
    "target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Our features will be\n",
    "x = customers.loc[target.index, features]\n",
    "x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 9.2: Preprocessing**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocess the data\n",
    "# Use sklearn's pipeline to working with train/test splits easier\n",
    "# You can use make_column_transformer and make_column_selector for this\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "# You can use the Standard scaler for numeric data (dtype_include=np.number)\n",
    "# You can use the OneHotEncoder for categorical data (dtype_include=object)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(categories=[customers[s].unique() for s in ['country', 'client_group']]), make_column_selector(dtype_include=object))\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test the pipeline\n",
    "ct.fit_transform(x).toarray()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 9.3: Modeling**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First Benchmark**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We want to measure our performance against a really simple benchmark\n",
    "# Always predict the average time between orders\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "bench1 = DummyRegressor(strategy='constant', constant=target.mean())\n",
    "bench1.fit(x, target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Second Benchmark**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This more advanced benchmark takes the average time between orders of each customer\n",
    "bench2 = target.groupby(level=0).mean().loc[customers.loc[target.index].index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 9.3.1: Simple solution**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We can start with a simple model first\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a pipeline with your preprocessing pipeline and the LinearRegression() model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(ct, LinearRegression())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evalaute the pipeline against the benchmarks\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(f'[ML model]: {np.mean(cross_val_score(pipe, x, target, scoring=make_scorer(mean_squared_error)))}')\n",
    "\n",
    "print(f'[Bench 1]: {mean_squared_error(target, bench1.predict(x))}')\n",
    "\n",
    "print(f'[Bench 2]: {mean_squared_error(target, bench2)}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **9.3.2: Optimization**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Use some form of optimization to find a model that performs better than benchmark 1**  \n",
    "Options:\n",
    "- Manual search\n",
    "- Grid search\n",
    "- Random search\n",
    "- Bayesian optimization\n",
    "\n",
    "Tip: You can treat the model as a hyperparameter and search for the best model and the best hyperparameter combination at the same time.\n",
    "\n",
    "Tip: It might suffice to just use a complex instead of a linear model\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evalaute the pipeline against the benchmarks\n",
    "\n",
    "print(f'[ML model]: {np.mean(cross_val_score(pipe, x, target, scoring=make_scorer(mean_squared_error)))}')\n",
    "\n",
    "print(f'[Bench 1]: {mean_squared_error(target, bench1.predict(x))}')\n",
    "\n",
    "print(f'[Bench 2]: {mean_squared_error(target, bench2)}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 9.3.3: Outlier detection and Segmentation**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We can aggregate the order_history data to visualize the behavior of each of our customers\n",
    "avg_order_freq = target.groupby(level=0).mean()\n",
    "avg_order_size = order_history.groupby(level=-1).mean()\n",
    "\n",
    "agg_customers = avg_order_freq.to_frame().join(avg_order_size)\n",
    "agg_customers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agg_customers.plot.scatter(x='target', y='volume')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this image we can see two thinks:\n",
    "- There seem to be clusters of similar behaving customers (segement the data and build one model per segment)\n",
    "- There are a lot of outliers that can reduce our prediction accuracy (remove outliers to improved the learned function)\n",
    "\n",
    "Depending on the algorithm you choose you can segment the data and do outlier removal at the same time or do it separately.\n",
    "\n",
    "Then train one model per segment. Use some form of Hyperparameter optimization to automatically find the best one for each segment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 9.4: Evaluation**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the work above, evaluate your final model on the test dataset.\n",
    "\n",
    "You can use the complete training dataset for training now.\n",
    "\n",
    "**What is the final evaluation performance you achieve on the test set?**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the test data\n",
    "test_customers = pd.read_csv(\n",
    "    'customers.csv',\n",
    "    index_col='customer_id',\n",
    "    parse_dates=['birth_date', 'customer_since'])\n",
    "test_order_history = pd.read_csv(\n",
    "    'order_history.csv',\n",
    "    index_col=[0, 1],\n",
    "    parse_dates=True)\n",
    "test_order_history.index.names = ['target', 'customer_id']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bi_deep_learning-M-dGzlNK': pipenv)"
  },
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}