{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Module 4: Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Setup the matplotlib styling\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Try to use the BI style sheet for plots\n",
    "    plt.style.use('matplotlibrc')\n",
    "    plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[(136/256, 76/256, 255/256), (60/256, 170/256, 207/256), (12/256, 229/256, 177/256)]) \n",
    "    \n",
    "    colors = [(0.53125, 0.296875, 0.99609375), (0.453125, 0.3984375, 0.9453125), (0.375, 0.4921875, 0.89453125), (0.3046875, 0.578125, 0.8515625), (0.234375, 0.6640625, 0.80859375), (0.16015625, 0.75390625, 0.76171875), (0.09375, 0.8359375, 0.72265625), (0.046875, 0.89453125, 0.69140625), (0.0, 0.875, 0.6640625)]\n",
    "    bicmap = LinearSegmentedColormap.from_list(name='BIcmp', \n",
    "                                                colors=colors,\n",
    "                                                N=len(colors))\n",
    "    cm_bright = ListedColormap([(0.53125, 0.296875, 0.99609375), (12/256, 229/256, 177/256)])\n",
    "except:\n",
    "    bicmap = plt.cm.BuGn \n",
    "    colors = ['r', 'g', 'b']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 4.1:**\n",
    "Fill in the blanks in the following sentences:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the case of underfitting, the ``Training`` error is high.  \n",
    "In the case of overfitting, the ``Training`` error is low but the ``Test`` error is high.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 4.2:**\n",
    "\n",
    "You are a Data Scientist in an advertising company. Given a single continuous parameter x, you have to predict a continuous target variable y. You decided to use a polynomial regression model (remember that you can use make_pipeline from sklearn to do that if you want). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.1:** \n",
    "Write two functions in python:\n",
    "\n",
    "fit_model(x, y, degree)\n",
    "Given a a single feature ‘x’ and a target variable ‘y’ and the degree for the polynomial regression, this function should compute the actual model and return it.\n",
    "\n",
    "evaluate_model(model, x, y)\n",
    "Given a model and a dataset with a single feature ‘x’ and a target variable ‘y’, this functions should compute the MAE (Mean Absolute Error) of the model and return it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def fit_model(x, y, degree):\n",
    "    poly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_reg.fit(x, y)\n",
    "    return poly_reg\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    return mean_absolute_error(y, model.predict(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.2:** \n",
    "\n",
    "For each value of the hyperparameter ‘d’ in 1,2,3,…,20,\n",
    "1. Train a model on the given data in train.csv\n",
    "2. Evaluate the model on test.csv\n",
    "\n",
    "Which value for the hyperparameter ‘d’ is best suited for putting the model into production?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train_x = train[['x']].values\n",
    "train_y = train['y'].values\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          x         y\n",
       "0  0.000000  0.000000\n",
       "1  0.392699  0.882683\n",
       "2  0.785398  0.707107\n",
       "3  1.570796  1.000000\n",
       "4  1.963495  1.423880"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.882683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.785398</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.570796</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.963495</td>\n",
       "      <td>1.423880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test_x = test[['x']].values\n",
    "test_y = test['y'].values\n",
    "test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          x         y\n",
       "0  1.178097  0.423880\n",
       "1  2.748894 -0.117317\n",
       "2  4.319690 -1.423880\n",
       "3  5.890486 -0.882683"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.178097</td>\n",
       "      <td>0.423880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.748894</td>\n",
       "      <td>-0.117317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.319690</td>\n",
       "      <td>-1.423880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.890486</td>\n",
       "      <td>-0.882683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "maes = []\n",
    "for d in range(1, 20+1):\n",
    "    model = fit_model(train_x, train_y, d)\n",
    "    mae = evaluate_model(model, test_x, test_y)\n",
    "    print(f'Degree {d} with error: {mae:0.3f}')\n",
    "    maes.append(mae)\n",
    "\n",
    "# Outputs the rank of each degree\n",
    "dict(zip(list(range(1, 21)), np.argsort(np.argsort(np.array(maes)))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Degree 1 with error: 0.528\n",
      "Degree 2 with error: 0.537\n",
      "Degree 3 with error: 0.641\n",
      "Degree 4 with error: 0.650\n",
      "Degree 5 with error: 0.658\n",
      "Degree 6 with error: 0.673\n",
      "Degree 7 with error: 0.561\n",
      "Degree 8 with error: 0.608\n",
      "Degree 9 with error: 0.683\n",
      "Degree 10 with error: 1.168\n",
      "Degree 11 with error: 0.922\n",
      "Degree 12 with error: 2.334\n",
      "Degree 13 with error: 2.386\n",
      "Degree 14 with error: 0.518\n",
      "Degree 15 with error: 6.280\n",
      "Degree 16 with error: 21.358\n",
      "Degree 17 with error: 27.736\n",
      "Degree 18 with error: 158.650\n",
      "Degree 19 with error: 1580.745\n",
      "Degree 20 with error: 799.845\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 5,\n",
       " 4: 6,\n",
       " 5: 7,\n",
       " 6: 8,\n",
       " 7: 3,\n",
       " 8: 4,\n",
       " 9: 9,\n",
       " 10: 11,\n",
       " 11: 10,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 0,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 19,\n",
       " 20: 18}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best degree is 14!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.3:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "val = pd.read_csv('data/val.csv')\n",
    "val_x = val[['x']].values\n",
    "val_y = val['y'].values\n",
    "val.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          x         y\n",
       "0  0.000000 -0.011248\n",
       "1  0.006289  0.101211\n",
       "2  0.012579  0.106121\n",
       "3  0.018868 -0.103820\n",
       "4  0.025158  0.070877"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.101211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.106121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>-0.103820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025158</td>\n",
       "      <td>0.070877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Since there are 1000 ad requests coming in each hour, the hourly company profit for a real-world application is computed as 1000*(1-MAE) where MAE is the mean average error.\n",
    "\n",
    "1.\tRetrain the model on the whole dataset using this best suitable degree d. We simulate that you have put the model into production by providing a lot of real-world data (val.csv) that comes in after putting the model in production.\n",
    "What is the company profit (hourly and yearly) of that model on the real-world data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Create the whole dataset\n",
    "x = np.append(train_x, test_x, axis=0)\n",
    "y = np.append(train_y, test_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Retrain the model on the chosen degree\n",
    "model_14 = fit_model(x, y, 14)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "mae_14 = evaluate_model(model_14, val_x, val_y)\n",
    "mae_14"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3894963698983938"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Calculate the profit of the model\n",
    "profit_14 = 1000 * (1-mae_14)\n",
    "profit_14"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "610.5036301016063"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.\tRetrain the model with degree d=3 on the whole dataset and evaluate it on val.csv. What is the company profit (hourly and yearly) of that model on the real-world data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Retrain the model with degree 3\n",
    "model_3 = fit_model(x, y, 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Evaluate the model\n",
    "mae_3 = evaluate_model(model_3, val_x, val_y)\n",
    "mae_3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.13178017956437377"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Calculate the profits of the model\n",
    "profit_3 = 1000 * (1-mae_3)\n",
    "profit_3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "868.2198204356262"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.\tExplain your finding and decide which model should be put into production."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model with 14 degrees is underperforming in production because with our hyperparameter optimization we overfitted the test set.\n",
    "If we would use the degree 3 model we would earn 250$ more per hour more."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "250*24*365"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2190000"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We earn 2.190.000$ more in year with model 3."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.4**\n",
    "\n",
    "Provide a method how to evaluate the performance of a hyperparameter more reliably."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The correct method would be to use leave-one-out cross validation for each degree on the combination of train and test set together."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Example of correct Hyperparameter evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "maes = []\n",
    "for d in range(1, 20+1):\n",
    "    model = fit_model(train_x, train_y, d)\n",
    "    mae = np.mean(cross_val_score(model, x, y, scoring=make_scorer(mean_absolute_error)))\n",
    "    print(f'Degree {d} with error: {mae:0.3f}')\n",
    "    maes.append(mae)\n",
    "\n",
    "# Outputs the rank of each degree\n",
    "dict(zip(list(range(1, 21)), np.argsort(np.argsort(np.array(maes)))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Degree 1 with error: 0.518\n",
      "Degree 2 with error: 0.775\n",
      "Degree 3 with error: 0.510\n",
      "Degree 4 with error: 0.911\n",
      "Degree 5 with error: 1.581\n",
      "Degree 6 with error: 2.143\n",
      "Degree 7 with error: 17.570\n",
      "Degree 8 with error: 8.460\n",
      "Degree 9 with error: 149.075\n",
      "Degree 10 with error: 120.874\n",
      "Degree 11 with error: 495.826\n",
      "Degree 12 with error: 92.322\n",
      "Degree 13 with error: 5.291\n",
      "Degree 14 with error: 26.400\n",
      "Degree 15 with error: 69.051\n",
      "Degree 16 with error: 96.792\n",
      "Degree 17 with error: 48.804\n",
      "Degree 18 with error: 622.664\n",
      "Degree 19 with error: 17567.622\n",
      "Degree 20 with error: 35045.137\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 0,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 8,\n",
       " 8: 7,\n",
       " 9: 15,\n",
       " 10: 14,\n",
       " 11: 16,\n",
       " 12: 12,\n",
       " 13: 6,\n",
       " 14: 9,\n",
       " 15: 11,\n",
       " 16: 13,\n",
       " 17: 10,\n",
       " 18: 17,\n",
       " 19: 18,\n",
       " 20: 19}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the correct hyperparameter gets selected."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Bonus 1**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try some automated Hyperparameter Optimization."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Run the different HPO methods\n",
    "- What is the best value you can achieve with a SVM model?\n",
    "- Make some modifications to the methods to speed up the search\n",
    "- What method is the most efficient for this problem?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The problem dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=2,\n",
    "    n_repeated=2,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=4,\n",
    "    flip_y=0.01,\n",
    "    class_sep=0.5)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will try to optimize a support vector machine which has two important parameters for the parameters \"C\" and \"gamma\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Import necessary requirements\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from sklearn.utils.fixes import loguniform"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Define the search space for the Grid Search\n",
    "params = [\n",
    "  {'C': [0.1, 1, 10, 100, 1000, 2000], 'gamma': [0.005, 0.001 , 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Initialize GridSearch\n",
    "gcv = GridSearchCV(\n",
    "    estimator=svc,\n",
    "    param_grid=params,\n",
    "    n_jobs=-1,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# fit \n",
    "gcv.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100, 1000, 2000],\n",
       "                          'gamma': [0.005, 0.001, 0.0001], 'kernel': ['rbf']}])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Get the parameters that achieved the best performance\n",
    "gcv.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.005, 'kernel': 'rbf'}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Evaluate the model on unseen data\n",
    "g_model = SVC(**gcv.best_params_)\n",
    "g_model.fit(x_train, y_train)\n",
    "g_model.score(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our random search will be allowed to have as many runs as the GridSearch had."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "num_runs = len(gcv.cv_results_['params'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Import the necessary requirements\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Define the search space\n",
    "params = {\n",
    "    'C': loguniform(1e-1, 2e3),\n",
    "    'gamma': loguniform(1e-4, 1e-3),\n",
    "    'kernel': ['rbf']\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Initialize the Random Search\n",
    "rcv = RandomizedSearchCV(\n",
    "    estimator=svc,\n",
    "    param_distributions=params,\n",
    "    n_iter=20\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Perform the fit\n",
    "rcv.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fb827f9a910>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fb827f847c0>,\n",
       "                                        'kernel': ['rbf']})"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Get the hyperparameters that created the best performance\n",
    "rcv.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 17.370675563958468, 'gamma': 0.0007399354764248056, 'kernel': 'rbf'}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Evaluate model\n",
    "r_model = SVC(**rcv.best_params_)\n",
    "r_model.fit(x_train, y_train)\n",
    "r_model.score(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use a more intelligent method to find the best hyperparameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# First install scikit-optimize\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-optimize"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scikit-optimize in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from scikit-optimize) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from scikit-optimize) (1.0.1)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from scikit-optimize) (21.8.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from scikit-optimize) (1.21.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from scikit-optimize) (1.7.1)\n",
      "Requirement already satisfied: PyYAML in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Import the necessary libraries\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Redefine the search space from Random Search as dimensions\n",
    "space = [\n",
    "    Real(low=1e-1, high=2e3, prior='log-uniform', name='C'),\n",
    "    Real(low=1e-4, high=1e-3, prior='log-uniform', name='gamma'),\n",
    "    Categorical(categories=['rbf'], transform='identity', prior=None, name='kernel')\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Since Bayesian Optimization CV is currently broken, we will use the gp_minimize() function\n",
    "\n",
    "@use_named_args(dimensions=space)\n",
    "def func(**params):\n",
    "    svc = SVC(**params)\n",
    "    svc.fit(x_train, y_train)\n",
    "    score = svc.score(x_test, y_test)\n",
    "    # gp_minimize minimizes, so convert accuracy to inverse\n",
    "    return 1 - score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Start the search procress with the same number of runs\n",
    "res = gp_minimize(func, dimensions=space, n_calls=num_runs, n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Get the best parameters\n",
    "res.x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1830.2886345935435, 0.0003986729114551175, 'rbf']"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Evaluate model\n",
    "bo_model = SVC(**dict(zip(['C', 'gamma', 'kernel'], res.x)))\n",
    "bo_model.fit(x_train, y_train)\n",
    "bo_model.score(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Bonus:**\n",
    "Perform the same optimization on the dataset, but this time use the MLPClassifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- What are problems you run into?\n",
    "- What can you do to solve them?\n",
    "- What is the best accuracy you can achieve with a MLP model?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Define the search space\n",
    "space_mlp = [\n",
    "    Real(low=1e-4, high=1e0, prior='log-uniform', name='learning_rate_init'),\n",
    "    Categorical(categories=['constant', 'invscaling', 'adaptive'], transform='identity', prior=None, name='learning_rate'),\n",
    "    Real(low=1e-4, high=1e-2, prior='log-uniform', name='alpha'),\n",
    "    Categorical(categories=['identity', 'logistic', 'tanh', 'relu'], transform='identity', prior=None, name='activation'),\n",
    "    Categorical(categories=['lbfgs', 'sgd', 'adam'], transform='identity', prior=None, name='solver'),\n",
    "    Integer(low=1, high=4, name='num_layers'),\n",
    "    Integer(low=24, high=128, name='n1'),\n",
    "    Integer(low=24, high=128, name='n2'),\n",
    "    Integer(low=24, high=128, name='n3'),\n",
    "    Integer(low=24, high=128, name='n4'),\n",
    "]\n",
    "# Define the target function\n",
    "@use_named_args(dimensions=space_mlp)\n",
    "def func_mlp(**params):\n",
    "    num_layers = params['num_layers']\n",
    "    neurons_in_layer = [params['n1'], params['n2'], params['n3'], params['n4']]\n",
    "    params['hidden_layer_sizes'] = tuple([i for n, i in zip(range(num_layers), neurons_in_layer)])\n",
    "\n",
    "    del params['num_layers']\n",
    "    del params['n1']\n",
    "    del params['n2']\n",
    "    del params['n3']\n",
    "    del params['n4']\n",
    "\n",
    "    mlp = MLPClassifier(**params)\n",
    "    mlp.fit(x_train, y_train)\n",
    "    score = mlp.score(x_test, y_test)\n",
    "    # gp_minimize minimizes, so convert accuracy to inverse\n",
    "    return 1 - score\n",
    "# Perform the minimization\n",
    "res_mlp = gp_minimize(func_mlp, dimensions=space_mlp, n_calls=40, n_jobs=-1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nuls/.local/share/virtualenvs/bi_deep_learning-M-dGzlNK/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "1 - res_mlp.fun"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "res_mlp.x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.12621151482546025,\n",
       " 'constant',\n",
       " 0.0032137365160487008,\n",
       " 'relu',\n",
       " 'lbfgs',\n",
       " 4,\n",
       " 128,\n",
       " 40,\n",
       " 49,\n",
       " 115]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "params_dict = dict(zip(['learning_rate_init', 'learning_rate', 'alpha', 'activation', 'solver', 'num_layers', 'n1', 'n2', 'n3', 'n4'], res_mlp.x))\n",
    "params_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'learning_rate_init': 0.12621151482546025,\n",
       " 'learning_rate': 'constant',\n",
       " 'alpha': 0.0032137365160487008,\n",
       " 'activation': 'relu',\n",
       " 'solver': 'lbfgs',\n",
       " 'num_layers': 4,\n",
       " 'n1': 128,\n",
       " 'n2': 40,\n",
       " 'n3': 49,\n",
       " 'n4': 115}"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Perform adaptation from above\n",
    "num_layers = params_dict['num_layers']\n",
    "neurons_in_layer = [params_dict['n1'], params_dict['n2'], params_dict['n3'], params_dict['n4']]\n",
    "params_dict['hidden_layer_sizes'] = tuple([i for n, i in zip(range(num_layers), neurons_in_layer)])\n",
    "\n",
    "del params_dict['num_layers']\n",
    "del params_dict['n1']\n",
    "del params_dict['n2']\n",
    "del params_dict['n3']\n",
    "del params_dict['n4']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "mlp_model = MLPClassifier(**params_dict)\n",
    "mlp_model.fit(x_train, y_train)\n",
    "mlp_model.score(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We overfit the training set with our HPO"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bi_deep_learning-M-dGzlNK': pipenv)"
  },
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}