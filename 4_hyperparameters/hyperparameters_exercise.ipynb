{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Module 4: Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setup the matplotlib styling\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Try to use the BI style sheet for plots\n",
    "    plt.style.use('matplotlibrc')\n",
    "    plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[(136/256, 76/256, 255/256), (60/256, 170/256, 207/256), (12/256, 229/256, 177/256)]) \n",
    "    \n",
    "    colors = [(0.53125, 0.296875, 0.99609375), (0.453125, 0.3984375, 0.9453125), (0.375, 0.4921875, 0.89453125), (0.3046875, 0.578125, 0.8515625), (0.234375, 0.6640625, 0.80859375), (0.16015625, 0.75390625, 0.76171875), (0.09375, 0.8359375, 0.72265625), (0.046875, 0.89453125, 0.69140625), (0.0, 0.875, 0.6640625)]\n",
    "    bicmap = LinearSegmentedColormap.from_list(name='BIcmp', \n",
    "                                                colors=colors,\n",
    "                                                N=len(colors))\n",
    "    cm_bright = ListedColormap([(0.53125, 0.296875, 0.99609375), (12/256, 229/256, 177/256)])\n",
    "except:\n",
    "    bicmap = plt.cm.BuGn \n",
    "    colors = ['r', 'g', 'b']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 4.1:**\n",
    "Fill in the blanks in the following sentences:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the case of underfitting, the ___________ error is high.  \n",
    "In the case of overfitting, the ___________ error is low but the ___________ error is high.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 4.2:**\n",
    "\n",
    "You are a Data Scientist in an advertising company. Given a single continuous parameter x, you have to predict a continuous target variable y. You decided to use a polynomial regression model (remember that you can use make_pipeline from sklearn to do that if you want). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.1:** \n",
    "Write two functions in python:\n",
    "\n",
    "fit_model(x, y, degree)\n",
    "Given a a single feature ‘x’ and a target variable ‘y’ and the degree for the polynomial regression, this function should compute the actual model and return it.\n",
    "\n",
    "evaluate_model(model, x, y)\n",
    "Given a model and a dataset with a single feature ‘x’ and a target variable ‘y’, this functions should compute the MAE (Mean Absolute Error) of the model and return it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def fit_model(x, y, degree):\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    # TODO\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.2:** \n",
    "\n",
    "For each value of the hyperparameter ‘d’ in 1,2,3,…,20,\n",
    "1. Train a model on the given data in train.csv\n",
    "2. Evaluate the model on test.csv\n",
    "\n",
    "Which value for the hyperparameter ‘d’ is best suited for putting the model into production?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train_x = train[['x']].values\n",
    "train_y = train['y'].values\n",
    "train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test_x = test[['x']].values\n",
    "test_y = test['y'].values\n",
    "test.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.3:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val = pd.read_csv('data/val.csv')\n",
    "val_x = val[['x']].values\n",
    "val_y = val['y'].values\n",
    "val.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Since there are 1000 ad requests coming in each hour, the hourly company profit for a real-world application is computed as 1000*(1-MAE) where MAE is the mean average error.\n",
    "\n",
    "1.\tRetrain the model on the whole dataset using this best suitable degree d. We simulate that you have put the model into production by providing a lot of real-world data (val.csv) that comes in after putting the model in production.\n",
    "What is the company profit (hourly and yearly) of that model on the real-world data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the whole dataset\n",
    "x = np.append(train_x, test_x, axis=0)\n",
    "y = np.append(train_y, test_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retrain the model on the chosen degree\n",
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate the profit of the model\n",
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.\tRetrain the model with degree d=3 on the whole dataset and evaluate it on val.csv. What is the company profit (hourly and yearly) of that model on the real-world data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retrain the model with degree 3\n",
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model\n",
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate the profits of the model\n",
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.\tExplain your finding and decide which model should be put into production."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Exercise 4.2.4**\n",
    "\n",
    "Provide a method how to evaluate the performance of a hyperparameter more reliably."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Bonus 1**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try some automated Hyperparameter Optimization."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Run the different HPO methods\n",
    "- What is the best value you can achieve with a SVM model?\n",
    "- Make some modifications to the methods to speed up the search\n",
    "- What method is the most efficient for this problem?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The problem dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=2,\n",
    "    n_repeated=2,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=4,\n",
    "    flip_y=0.01,\n",
    "    class_sep=0.5)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will try to optimize a support vector machine which has two important parameters for the parameters \"C\" and \"gamma\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import necessary requirements\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from sklearn.utils.fixes import loguniform"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the search space for the Grid Search\n",
    "params = [\n",
    "  {'C': [0.1, 1, 10, 100, 1000, 2000], 'gamma': [0.005, 0.001 , 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize GridSearch\n",
    "gcv = GridSearchCV(\n",
    "    estimator=svc,\n",
    "    param_grid=params,\n",
    "    n_jobs=-1,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fit \n",
    "gcv.fit(x_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the parameters that achieved the best performance\n",
    "gcv.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model on unseen data\n",
    "g_model = SVC(**gcv.best_params_)\n",
    "g_model.fit(x_train, y_train)\n",
    "g_model.score(x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our random search will be allowed to have as many runs as the GridSearch had."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_runs = len(gcv.cv_results_['params'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import the necessary requirements\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the search space\n",
    "params = {\n",
    "    'C': loguniform(1e-1, 2e3),\n",
    "    'gamma': loguniform(1e-4, 1e-3),\n",
    "    'kernel': ['rbf']\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize the Random Search\n",
    "rcv = RandomizedSearchCV(\n",
    "    estimator=svc,\n",
    "    param_distributions=params,\n",
    "    n_iter=20\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perform the fit\n",
    "rcv.fit(x_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the hyperparameters that created the best performance\n",
    "rcv.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate model\n",
    "r_model = SVC(**rcv.best_params_)\n",
    "r_model.fit(x_train, y_train)\n",
    "r_model.score(x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use a more intelligent method to find the best hyperparameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First install scikit-optimize\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-optimize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import the necessary libraries\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Redefine the search space from Random Search as dimensions\n",
    "space = [\n",
    "    Real(low=1e-1, high=2e3, prior='log-uniform', name='C'),\n",
    "    Real(low=1e-4, high=1e-3, prior='log-uniform', name='gamma'),\n",
    "    Categorical(categories=['rbf'], transform='identity', prior=None, name='kernel')\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Since Bayesian Optimization CV is currently broken, we will use the gp_minimize() function\n",
    "\n",
    "@use_named_args(dimensions=space)\n",
    "def func(**params):\n",
    "    svc = SVC(**params)\n",
    "    svc.fit(x_train, y_train)\n",
    "    score = svc.score(x_test, y_test)\n",
    "    # gp_minimize minimizes, so convert accuracy to inverse\n",
    "    return 1 - score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Start the search procress with the same number of runs\n",
    "res = gp_minimize(func, dimensions=space, n_calls=num_runs, n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the best parameters\n",
    "res.x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate model\n",
    "bo_model = SVC(**dict(zip(['C', 'gamma', 'kernel'], res.x)))\n",
    "bo_model.fit(x_train, y_train)\n",
    "bo_model.score(x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Bonus 2:**\n",
    "Perform the same optimization on the dataset, but this time use the MLPClassifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- What are problems you run into?\n",
    "- What can you do to solve them?\n",
    "- What is the best accuracy you can achieve with a MLP model?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bi_deep_learning-M-dGzlNK': pipenv)"
  },
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}