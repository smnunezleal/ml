{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Modul 8: Deep Learning and NLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Setup**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import pathlib"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-13 19:18:09.777406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-13 19:18:09.777717: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preload word embeddings\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Load pre-trained word embeddings\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-09-13 18:41:53--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-09-13 18:41:54--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-09-13 18:41:54--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M   939KB/s    in 14m 33s \n",
      "\n",
      "2021-09-13 18:56:29 (964 KB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
      "\n",
      "[glove.6B.zip]\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
      "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "!unzip glove.6B.zip.1 -d glove.6B"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  glove.6B.zip.1\n",
      "  inflating: glove.6B.txt/glove.6B.50d.txt  \n",
      "  inflating: glove.6B.txt/glove.6B.100d.txt  \n",
      "  inflating: glove.6B.txt/glove.6B.200d.txt  \n",
      "  inflating: glove.6B.txt/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **The data**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)\n",
    "\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['sci.crypt', 'misc.forsale', 'sci.med', 'rec.sport.hockey', 'alt.atheism', 'comp.sys.mac.hardware', 'comp.os.ms-windows.misc', 'talk.politics.mideast', 'soc.religion.christian', 'talk.politics.misc', 'talk.politics.guns', 'rec.motorcycles', 'comp.windows.x', 'comp.graphics', 'rec.sport.baseball', 'comp.sys.ibm.pc.hardware', 'sci.electronics', 'sci.space', 'rec.autos', 'talk.religion.misc']\n",
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['38253', '38469', '39656', '38291', '38334']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Get an example of what the dataset contains\n",
    "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Newsgroups: comp.graphics\n",
      "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
      "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
      "Subject: Looking for Brain in CAD\n",
      "Message-ID: <c285m+p@rpi.edu>\n",
      "Nntp-Posting-Host: nason110.its.rpi.edu\n",
      "Reply-To: mabusj@rpi.edu\n",
      "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
      "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
      "Lines: 7\n",
      "\n",
      "Jasen Mabus\n",
      "RPI student\n",
      "\n",
      "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
      "\n",
      "Thank you in advance,\n",
      "Jasen Mabus  \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Unpack and load the data\n",
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create a training and validation dataset\n",
    "\n",
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 8.1: Vectorization**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "# Create a TextVectorization with 20000 max_tokens and an output_sequence_length of 200\n",
    "# Adapt the vectorizer to the data\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "vectorizer.adapt(text_ds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-13 19:18:18.890938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-13 19:18:18.891495: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-13 19:18:18.891589: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CE43859): /proc/driver/nvidia/version does not exist\n",
      "2021-09-13 19:18:18.894136: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-13 19:18:20.159478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# We can have a look at the vocabulary index\n",
    "vectorizer.get_vocabulary()[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'of']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# If we vectorize a sentence we get\n",
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([   2, 3664, 1805,   15,    2, 8148])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 8.2: Embeddings**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Extract the installed word embeddings\n",
    "# We use the smallest available embedding 50\n",
    "path_to_glove_file = 'glove.6B/glove.6B.50d.txt'\n",
    "\n",
    "# Every entry in the file contains the word followed by the coefficients\n",
    "# Extract all the words into a dictionary with key (word) value(vector) mapping \n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The embedding is a simple NumPy matrix where entry at index i is the pre-trained vector for the word of index i in our vectorizer's vocabulary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Create an embedding matrix to send it to the embedding layer later\n",
    "\n",
    "# Create another mapping for the vocabulary learned by the vectorizer\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "\n",
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "# Join both dictionaries in the numpy array\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 17956 words (2044 misses)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Create the embedding layer\n",
    "# We pass our embedding matrix as the state of the matrix and set it to not trainable\n",
    "embedding_layer = layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 8.3: Modeling**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Build a convoluational model that takes the vectorized words as input\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 50)          1000100   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 1,215,416\n",
      "Trainable params: 215,316\n",
      "Non-trainable params: 1,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Use right padding to make each sentence the same size\n",
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Fit the model\n",
    "# With 20 epochs this should take about 3 minutes\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 12s 74ms/step - loss: 2.6071 - acc: 0.1558 - val_loss: 2.1245 - val_acc: 0.2748\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 11s 90ms/step - loss: 1.9266 - acc: 0.3320 - val_loss: 1.5857 - val_acc: 0.4554\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 9s 74ms/step - loss: 1.5967 - acc: 0.4401 - val_loss: 1.3659 - val_acc: 0.5396\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 9s 74ms/step - loss: 1.3808 - acc: 0.5256 - val_loss: 1.3038 - val_acc: 0.5596\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 1.2336 - acc: 0.5791 - val_loss: 1.1625 - val_acc: 0.6032\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 10s 80ms/step - loss: 1.0940 - acc: 0.6205 - val_loss: 1.1549 - val_acc: 0.6084\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 10s 78ms/step - loss: 0.9865 - acc: 0.6630 - val_loss: 1.0716 - val_acc: 0.6422\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 10s 78ms/step - loss: 0.8923 - acc: 0.6882 - val_loss: 1.0757 - val_acc: 0.6427\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 10s 76ms/step - loss: 0.7971 - acc: 0.7247 - val_loss: 1.0633 - val_acc: 0.6482\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 9s 75ms/step - loss: 0.7150 - acc: 0.7521 - val_loss: 1.0584 - val_acc: 0.6604\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 10s 76ms/step - loss: 0.6329 - acc: 0.7743 - val_loss: 1.1043 - val_acc: 0.6527\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 9s 73ms/step - loss: 0.5620 - acc: 0.8053 - val_loss: 1.0909 - val_acc: 0.6717\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 10s 79ms/step - loss: 0.5026 - acc: 0.8242 - val_loss: 1.0785 - val_acc: 0.6754\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 0.4514 - acc: 0.8429 - val_loss: 1.1628 - val_acc: 0.6674\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.4028 - acc: 0.8640 - val_loss: 1.1458 - val_acc: 0.6864\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.3650 - acc: 0.8753 - val_loss: 1.1734 - val_acc: 0.6849\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.3218 - acc: 0.8922 - val_loss: 1.1812 - val_acc: 0.6852\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 0.2906 - acc: 0.8999 - val_loss: 1.5174 - val_acc: 0.6544\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 9s 73ms/step - loss: 0.2648 - acc: 0.9119 - val_loss: 1.8684 - val_acc: 0.6094\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 10s 77ms/step - loss: 0.2353 - acc: 0.9208 - val_loss: 1.5175 - val_acc: 0.6787\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fb8da3d30>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Bonus: Query the model**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Create an end-to-end model\n",
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "sentence = [['Put your text here']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "probabilities = end_to_end_model.predict(sentence)\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'talk.politics.guns'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Exercise 8.4: Recurrent Models**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = embedding_layer = layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# Add a classifier\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, preds)\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 50)          1000100   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         58880     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 1,160,376\n",
      "Trainable params: 160,276\n",
      "Non-trainable params: 1,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Compule the model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Fit the model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 89s 681ms/step - loss: 2.3852 - acc: 0.2272 - val_loss: 2.1526 - val_acc: 0.2663\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 1.9227 - acc: 0.3512 - val_loss: 1.8041 - val_acc: 0.3598\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 82s 654ms/step - loss: 1.7385 - acc: 0.4056 - val_loss: 1.5671 - val_acc: 0.4564\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 1.6107 - acc: 0.4424 - val_loss: 1.7591 - val_acc: 0.3773\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 79s 635ms/step - loss: 1.5388 - acc: 0.4714 - val_loss: 1.4550 - val_acc: 0.4964\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 81s 648ms/step - loss: 1.4351 - acc: 0.5070 - val_loss: 1.4258 - val_acc: 0.5101\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 85s 679ms/step - loss: 1.3685 - acc: 0.5313 - val_loss: 1.3516 - val_acc: 0.5314\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 73s 583ms/step - loss: 1.3089 - acc: 0.5550 - val_loss: 1.3074 - val_acc: 0.5566\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 76s 607ms/step - loss: 1.2528 - acc: 0.5719 - val_loss: 1.2960 - val_acc: 0.5694\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 1.1989 - acc: 0.5863 - val_loss: 1.1765 - val_acc: 0.5939\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 81s 643ms/step - loss: 1.1610 - acc: 0.6050 - val_loss: 1.1985 - val_acc: 0.5941\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 81s 646ms/step - loss: 1.1128 - acc: 0.6226 - val_loss: 1.1608 - val_acc: 0.6039\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 85s 681ms/step - loss: 1.0654 - acc: 0.6405 - val_loss: 1.1061 - val_acc: 0.6294\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 88s 709ms/step - loss: 1.0348 - acc: 0.6508 - val_loss: 1.1168 - val_acc: 0.6299\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 0.9792 - acc: 0.6670 - val_loss: 1.0961 - val_acc: 0.6372\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 81s 653ms/step - loss: 0.9478 - acc: 0.6786 - val_loss: 1.0537 - val_acc: 0.6494\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.9033 - acc: 0.6940 - val_loss: 1.0568 - val_acc: 0.6514\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.8641 - acc: 0.7083 - val_loss: 1.0299 - val_acc: 0.6679\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 84s 670ms/step - loss: 0.8283 - acc: 0.7183 - val_loss: 1.0187 - val_acc: 0.6699\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 80s 640ms/step - loss: 0.8006 - acc: 0.7298 - val_loss: 1.0042 - val_acc: 0.6672\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fb24ac580>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Bonus: Query the model**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Create an end-to-end model\n",
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "sentence = [['Put your text here']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "probabilities = end_to_end_model.predict(sentence)\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'talk.politics.mideast'"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bi_deep_learning-M-dGzlNK': pipenv)"
  },
  "interpreter": {
   "hash": "3a851e0f79b59b2bccaf1ffc2243b1acd0ae10df96b3f2ce733c4d83b39092de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}